{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"HyperQueue lets you build a computation plan consisting of a large amount of tasks and then execute it transparently over a system like SLURM/PBS. It dynamically groups jobs into SLURM/PBS jobs and distributes them to fully utilize allocated notes. You thus do not have to manually aggregate your tasks into SLURM/PBS jobs. Project repository: https://github.com/spirali/hyperqueue/ Submiting a simple task # Start server (e.g. on a login node or in a cluster partition) $ hq server start Submit a job (command echo 'Hello world' in this case) $ hq submit echo 'Hello world' Ask for computing resource Start worker manually $ hq worker start Automatic resource request [Not implemented yet] Manual request in PBS $ qsub <your-params-of-qsub> -- hq worker start Manual request in SLURM sbatch <your-params-of-sbatch> -- hq worker start Monitor the state of jobs $ hq jobs","title":"Overview"},{"location":"#submiting-a-simple-task","text":"Start server (e.g. on a login node or in a cluster partition) $ hq server start Submit a job (command echo 'Hello world' in this case) $ hq submit echo 'Hello world' Ask for computing resource Start worker manually $ hq worker start Automatic resource request [Not implemented yet] Manual request in PBS $ qsub <your-params-of-qsub> -- hq worker start Manual request in SLURM sbatch <your-params-of-sbatch> -- hq worker start Monitor the state of jobs $ hq jobs","title":"Submiting a simple task"},{"location":"cheatsheet/","text":"Cheatsheet #","title":"Cheatsheet"},{"location":"cheatsheet/#cheatsheet","text":"","title":"Cheatsheet"},{"location":"deployment/","text":"Deployment # This section describes, how to HyperQueue server Starting server # Server may run on any computer as long as computing nodes are able to connect to these machine. It is not necessary to be able to connect from server to computing nodes. In the most simple scenario, we expect that the user starts its own instance of HyperQueue directly on login of a HPC system. The server can be simply started by the following command: hq server start Note: The server opens two TCP/IP ports: one for submitting jobs and one for connecting workers. By default, these ports are automatically assigned by the operation system. A user does not remmber them, they are stored in the \"server directory\". Other components automatically reads these settings. Server directory # When a HQ server is started, it creates a server directory where it stores informations needed for submiting jobs and connecting workers. Important: Encryption keys are stored in the server directory. Who has access to server directory may submit jobs, connect workers to HyperQueue instance, and decrypt communication between HyperQueue components. By default, server directory is stored in $HOME/.hq-server . It may be changed via option --server-dir=<PATH> . In such case, all commands need to use the --server-dir settings. You can run more instances of HyperQueue under the same user. All you need is to set a different server directories for each instance. Stopping server # A server can be stopped by command: hq server stop Starting worker # A worker can be started by command. It reads server directory and connectes to the server. hq worker start Starting worker in PBS # qsub <qsub-settings> -- hq worker start Starting worker in SLURM # sbatch <qsub-settings> -- hq worker start List of workers # hq worker list Stopping worker # hq worker stop <id>","title":"Deployment"},{"location":"deployment/#deployment","text":"This section describes, how to HyperQueue server","title":"Deployment"},{"location":"deployment/#starting-server","text":"Server may run on any computer as long as computing nodes are able to connect to these machine. It is not necessary to be able to connect from server to computing nodes. In the most simple scenario, we expect that the user starts its own instance of HyperQueue directly on login of a HPC system. The server can be simply started by the following command: hq server start Note: The server opens two TCP/IP ports: one for submitting jobs and one for connecting workers. By default, these ports are automatically assigned by the operation system. A user does not remmber them, they are stored in the \"server directory\". Other components automatically reads these settings.","title":"Starting server"},{"location":"deployment/#server-directory","text":"When a HQ server is started, it creates a server directory where it stores informations needed for submiting jobs and connecting workers. Important: Encryption keys are stored in the server directory. Who has access to server directory may submit jobs, connect workers to HyperQueue instance, and decrypt communication between HyperQueue components. By default, server directory is stored in $HOME/.hq-server . It may be changed via option --server-dir=<PATH> . In such case, all commands need to use the --server-dir settings. You can run more instances of HyperQueue under the same user. All you need is to set a different server directories for each instance.","title":"Server directory"},{"location":"deployment/#stopping-server","text":"A server can be stopped by command: hq server stop","title":"Stopping server"},{"location":"deployment/#starting-worker","text":"A worker can be started by command. It reads server directory and connectes to the server. hq worker start","title":"Starting worker"},{"location":"deployment/#starting-worker-in-pbs","text":"qsub <qsub-settings> -- hq worker start","title":"Starting worker in PBS"},{"location":"deployment/#starting-worker-in-slurm","text":"sbatch <qsub-settings> -- hq worker start","title":"Starting worker in SLURM"},{"location":"deployment/#list-of-workers","text":"hq worker list","title":"List of workers"},{"location":"deployment/#stopping-worker","text":"hq worker stop <id>","title":"Stopping worker"},{"location":"install/","text":"Installation # Binary distribution # Download latest binary distribution from https://github.com/It4innovations/hyperqueue/releases/latest Unpack the downloaded archive: $ tar -xvzf hq-<version>-linux-x64.tar.gz Compilation from source codes # Requirements: Git, Rust Clone HyperQueue repository: $ git clone https://github.com/It4innovations/hyperqueue/ Build project: $ cargo build --release Final executable file will in ./target/release/hq","title":"Installation"},{"location":"install/#installation","text":"","title":"Installation"},{"location":"install/#binary-distribution","text":"Download latest binary distribution from https://github.com/It4innovations/hyperqueue/releases/latest Unpack the downloaded archive: $ tar -xvzf hq-<version>-linux-x64.tar.gz","title":"Binary distribution"},{"location":"install/#compilation-from-source-codes","text":"Requirements: Git, Rust Clone HyperQueue repository: $ git clone https://github.com/It4innovations/hyperqueue/ Build project: $ cargo build --release Final executable file will in ./target/release/hq","title":"Compilation from source codes"},{"location":"jobarrays/","text":"Not released yet; scheduled for release v0.2","title":"Job Arrays"},{"location":"jobs/","text":"Jobs # In the current version, a job is a single execution of a program. Submiting jobs # hq submit <program> <args1> ... HyperQueue assigns a unique job id when a job is submitted. Name of a job # Each job has assigned a name. It has only an informative character for the user. By default, the name is extracted from the job's program name. You can set a job name explicitly by: hq submit --name=<NAME> ... Information about jobs # List of all jobs: hq jobs Detailed information about a job: hq job <job-id> Output of the job # By default, job produces two files named stdout.<job-id> and stderr.<job-id> that contains standard output and standard error output in the. The files are by default placed in the directory where the job was submitted. Job states # Submitted | | v Waiting-----------------\\ | | | | v | Running-----------------| | | | | \\--------\\ | | | | v v v Finished Failed Canceled Submitted - Only an informative state that submit was successfull, immediately changed into \"Waiting\" state. Waiting - The job is waiting for start Running - The job is running in a worker Finished - The job was sucessfully finished Failed - The job failed. The error can be shown by hq job <job-id> . Canceled - The job was canceled by a user. Canceling jobs # hq cancel <job-id> A job cannot be canceled if it is already finished, failed, or canceled. Priorities # Not released yet, scheduled for release v0.3","title":"Jobs (Basics)"},{"location":"jobs/#jobs","text":"In the current version, a job is a single execution of a program.","title":"Jobs"},{"location":"jobs/#submiting-jobs","text":"hq submit <program> <args1> ... HyperQueue assigns a unique job id when a job is submitted.","title":"Submiting jobs"},{"location":"jobs/#name-of-a-job","text":"Each job has assigned a name. It has only an informative character for the user. By default, the name is extracted from the job's program name. You can set a job name explicitly by: hq submit --name=<NAME> ...","title":"Name of a job"},{"location":"jobs/#information-about-jobs","text":"List of all jobs: hq jobs Detailed information about a job: hq job <job-id>","title":"Information about jobs"},{"location":"jobs/#output-of-the-job","text":"By default, job produces two files named stdout.<job-id> and stderr.<job-id> that contains standard output and standard error output in the. The files are by default placed in the directory where the job was submitted.","title":"Output of the job"},{"location":"jobs/#job-states","text":"Submitted | | v Waiting-----------------\\ | | | | v | Running-----------------| | | | | \\--------\\ | | | | v v v Finished Failed Canceled Submitted - Only an informative state that submit was successfull, immediately changed into \"Waiting\" state. Waiting - The job is waiting for start Running - The job is running in a worker Finished - The job was sucessfully finished Failed - The job failed. The error can be shown by hq job <job-id> . Canceled - The job was canceled by a user.","title":"Job states"},{"location":"jobs/#canceling-jobs","text":"hq cancel <job-id> A job cannot be canceled if it is already finished, failed, or canceled.","title":"Canceling jobs"},{"location":"jobs/#priorities","text":"Not released yet, scheduled for release v0.3","title":"Priorities"},{"location":"resources/","text":"Not released yet, scheduled for release v0.2","title":"Resource Requests"}]}